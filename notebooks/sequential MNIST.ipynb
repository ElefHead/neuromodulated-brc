{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "print(tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download file\n",
    "data_path = Path(\"..\") / \"datasets\" / \"data\"\n",
    "if not data_path.is_dir():\n",
    "    data_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir=data_path)\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: 60000, Testing data samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "print(f\"Training data samples: {num_train_examples}, Testing data samples: {num_test_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 1 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 * 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.reshape(image, (-1, 1))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"../logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Using Neuromodulated Bistable RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bistablernn import NBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  NBR(units=num_hidden, input_shape=(28*28, num_input), use_bias=True, \n",
    "                   recurrent_dropout=0, unroll=False, activation = \"tanh\", \n",
    "                   recurrent_activation = \"sigmoid\"),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.002, beta_1=0.1),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 2.2995 - accuracy: 0.1129 - val_loss: 2.2895 - val_accuracy: 0.1208\n",
      "Epoch 2/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 2.2117 - accuracy: 0.1942 - val_loss: 2.0115 - val_accuracy: 0.3108\n",
      "Epoch 3/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 2.2017 - accuracy: 0.1817 - val_loss: 2.2116 - val_accuracy: 0.1663\n",
      "Epoch 4/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 2.1585 - accuracy: 0.2039 - val_loss: 2.0834 - val_accuracy: 0.2500\n",
      "Epoch 5/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 1.9795 - accuracy: 0.2734 - val_loss: 1.6951 - val_accuracy: 0.3702\n",
      "Epoch 6/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 1.3879 - accuracy: 0.5024 - val_loss: 0.9908 - val_accuracy: 0.6854\n",
      "Epoch 7/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.8014 - accuracy: 0.7287 - val_loss: 0.5543 - val_accuracy: 0.8174\n",
      "Epoch 8/35\n",
      "1875/1875 [==============================] - 83s 45ms/step - loss: 0.5230 - accuracy: 0.8232 - val_loss: 0.4359 - val_accuracy: 0.8469\n",
      "Epoch 9/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.4194 - accuracy: 0.8551 - val_loss: 0.3634 - val_accuracy: 0.8636\n",
      "Epoch 10/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.3486 - accuracy: 0.8798 - val_loss: 0.2919 - val_accuracy: 0.9019\n",
      "Epoch 11/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.2803 - accuracy: 0.9070 - val_loss: 0.2553 - val_accuracy: 0.9156\n",
      "Epoch 12/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.3823 - accuracy: 0.8701 - val_loss: 1.7739 - val_accuracy: 0.3193\n",
      "Epoch 13/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 1.0075 - accuracy: 0.6339 - val_loss: 0.4722 - val_accuracy: 0.8440\n",
      "Epoch 14/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.4150 - accuracy: 0.8603 - val_loss: 0.3158 - val_accuracy: 0.8999\n",
      "Epoch 15/35\n",
      "1875/1875 [==============================] - 83s 44ms/step - loss: 0.2847 - accuracy: 0.9076 - val_loss: 0.2242 - val_accuracy: 0.9288\n",
      "Epoch 16/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.2001 - accuracy: 0.9368 - val_loss: 0.1756 - val_accuracy: 0.9443\n",
      "Epoch 17/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.1634 - accuracy: 0.9486 - val_loss: 0.3345 - val_accuracy: 0.8850\n",
      "Epoch 18/35\n",
      "1843/1875 [============================>.] - ETA: 1s - loss: 0.1315 - accuracy: 0.9585"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.1592 - accuracy: 0.9483 - val_loss: 0.1199 - val_accuracy: 0.9599\n",
      "Epoch 25/35\n",
      "1875/1875 [==============================] - 83s 44ms/step - loss: 0.1326 - accuracy: 0.9576 - val_loss: 0.4429 - val_accuracy: 0.8589\n",
      "Epoch 26/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.1193 - accuracy: 0.9622 - val_loss: 0.1075 - val_accuracy: 0.9658\n",
      "Epoch 27/35\n",
      "1875/1875 [==============================] - 83s 44ms/step - loss: 0.1091 - accuracy: 0.9659 - val_loss: 0.1166 - val_accuracy: 0.9650\n",
      "Epoch 28/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0987 - accuracy: 0.9688 - val_loss: 0.0929 - val_accuracy: 0.9702\n",
      "Epoch 29/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0935 - accuracy: 0.9701 - val_loss: 0.0970 - val_accuracy: 0.9714\n",
      "Epoch 30/35\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0935 - accuracy: 0.9706 - val_loss: 0.1034 - val_accuracy: 0.9674\n",
      "Epoch 31/35\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0861 - accuracy: 0.9730 - val_loss: 0.0843 - val_accuracy: 0.9740\n",
      "Epoch 32/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0778 - accuracy: 0.9759 - val_loss: 0.0919 - val_accuracy: 0.9716\n",
      "Epoch 33/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0753 - accuracy: 0.9764 - val_loss: 0.0747 - val_accuracy: 0.9762\n",
      "Epoch 34/35\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0720 - accuracy: 0.9768 - val_loss: 0.0742 - val_accuracy: 0.9764\n",
      "Epoch 35/35\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0734 - accuracy: 0.9767 - val_loss: 0.0692 - val_accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa580135790>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=35, validation_data=eval_dataset, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "nbr (NBR)                    (None, 128)               50304     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 51,594\n",
      "Trainable params: 51,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0692 - accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06916925311088562, 0.978600025177002]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
