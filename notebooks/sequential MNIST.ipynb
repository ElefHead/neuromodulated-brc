{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "print(tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download file\n",
    "data_path = Path(\"..\") / \"datasets\" / \"data\"\n",
    "if not data_path.is_dir():\n",
    "    data_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir=data_path)\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: 60000, Testing data samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "print(f\"Training data samples: {num_train_examples}, Testing data samples: {num_test_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 1 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 * 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.reshape(image, (-1, 1))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"../logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Using Neuromodulated Bistable RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bistablernn import NBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  NBR(units=num_hidden, input_shape=(28*28, num_input), use_bias=True, \n",
    "                   recurrent_dropout=0, unroll=False, activation = \"tanh\", \n",
    "                   recurrent_activation = \"sigmoid\"),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.002, beta_1=0.1),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 2.1445 - accuracy: 0.1874 - val_loss: 2.3245 - val_accuracy: 0.1245\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 2.3040 - accuracy: 0.1217 - val_loss: 2.3256 - val_accuracy: 0.0892\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 2.3209 - accuracy: 0.1060 - val_loss: 2.3528 - val_accuracy: 0.0421\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 2.3108 - accuracy: 0.1126 - val_loss: 2.3159 - val_accuracy: 0.0929\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 2.3020 - accuracy: 0.1129 - val_loss: 2.3070 - val_accuracy: 0.1021\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 2.3111 - accuracy: 0.1128 - val_loss: 2.2876 - val_accuracy: 0.1061\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.9906 - accuracy: 0.2325 - val_loss: 1.8450 - val_accuracy: 0.3142\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.6007 - accuracy: 0.3662 - val_loss: 1.5082 - val_accuracy: 0.4462\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.7341 - accuracy: 0.3476 - val_loss: 2.1808 - val_accuracy: 0.1850\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 2.0960 - accuracy: 0.2477 - val_loss: 2.0443 - val_accuracy: 0.2688\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 2.0016 - accuracy: 0.2995 - val_loss: 1.9640 - val_accuracy: 0.3077\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.9372 - accuracy: 0.3341 - val_loss: 1.9063 - val_accuracy: 0.3314\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.8838 - accuracy: 0.3611 - val_loss: 1.8627 - val_accuracy: 0.4059\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 85s 46ms/step - loss: 1.8352 - accuracy: 0.3797 - val_loss: 1.8175 - val_accuracy: 0.3840\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 85s 46ms/step - loss: 1.7857 - accuracy: 0.4011 - val_loss: 1.7773 - val_accuracy: 0.3960\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.7337 - accuracy: 0.4172 - val_loss: 1.7244 - val_accuracy: 0.4257\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.6757 - accuracy: 0.4362 - val_loss: 1.6405 - val_accuracy: 0.4590\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.6054 - accuracy: 0.4599 - val_loss: 1.5723 - val_accuracy: 0.4710\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 1.5208 - accuracy: 0.4823 - val_loss: 1.4687 - val_accuracy: 0.5067\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.4020 - accuracy: 0.5203 - val_loss: 1.3621 - val_accuracy: 0.5419\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 85s 46ms/step - loss: 1.2629 - accuracy: 0.5599 - val_loss: 1.2204 - val_accuracy: 0.5935\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.1464 - accuracy: 0.5929 - val_loss: 1.0741 - val_accuracy: 0.6026\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 1.0114 - accuracy: 0.6367 - val_loss: 0.9462 - val_accuracy: 0.6482\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.8684 - accuracy: 0.6894 - val_loss: 0.9636 - val_accuracy: 0.6320\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.7285 - accuracy: 0.7428 - val_loss: 0.6089 - val_accuracy: 0.7883\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.5280 - accuracy: 0.8190 - val_loss: 0.4474 - val_accuracy: 0.8375\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.5459 - accuracy: 0.8194 - val_loss: 0.4053 - val_accuracy: 0.8659\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.3467 - accuracy: 0.8864 - val_loss: 0.2749 - val_accuracy: 0.9076\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.2833 - accuracy: 0.9080 - val_loss: 0.2367 - val_accuracy: 0.9241\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 85s 46ms/step - loss: 0.2334 - accuracy: 0.9258 - val_loss: 0.2089 - val_accuracy: 0.9352\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.1948 - accuracy: 0.9382 - val_loss: 0.2102 - val_accuracy: 0.9327\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.1578 - accuracy: 0.9503 - val_loss: 0.1266 - val_accuracy: 0.9600\n",
      "Epoch 33/100\n",
      "1673/1875 [=========================>....] - ETA: 8s - loss: 0.1931 - accuracy: 0.9433"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=100, validation_data=eval_dataset, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 128)               50304     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 51,594\n",
      "Trainable params: 51,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
